{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNDGpAbH2eoaErnK+/LHpyI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gus-1003/Antares/blob/main/antares_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Videos:"
      ],
      "metadata": {
        "id": "SzW3PtsJKNGp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KoHs2FpwrUyH"
      },
      "outputs": [],
      "source": [
        "def remove_rats(images):\n",
        "  \"\"\"\n",
        "  Removes noise from a set of images by computing the median image.\n",
        "\n",
        "  Args:\n",
        "      images (list): A list of input images.\n",
        "\n",
        "  Returns:\n",
        "      numpy.ndarray: The median image, after noise removal.\n",
        "  \"\"\"\n",
        "  import numpy as np\n",
        "\n",
        "  # Convert each image in the list to a NumPy array\n",
        "  images_array = [np.array(image) for image in images]\n",
        "\n",
        "  # Compute the median image along the specified axis\n",
        "  median_image = np.median(images_array, axis=0)\n",
        "\n",
        "  # Convert the median image data type to unsigned 8-bit integer\n",
        "  median_image = median_image.astype('uint8')\n",
        "\n",
        "  return median_image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_frames(video_package, image_output):\n",
        "    \"\"\"\n",
        "    Extracts frames from videos in a video package and saves them as images.\n",
        "\n",
        "    Args:\n",
        "        video_package (list): A list of video file paths.\n",
        "        image_output (str): The directory where extracted images will be saved.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    import os\n",
        "    import cv2\n",
        "    import numpy as np\n",
        "\n",
        "\n",
        "    for video in video_package:\n",
        "        if not os.path.exists(video):\n",
        "            print(f\"The video '{video}' doesn't exist.\")\n",
        "            return\n",
        "\n",
        "        vidcap = cv2.VideoCapture(video)\n",
        "\n",
        "        if not vidcap.isOpened():\n",
        "            print(f\"Failed to open the video '{video}'.\")\n",
        "            return\n",
        "\n",
        "        images = []\n",
        "        success, image = vidcap.read()\n",
        "        cont = 0\n",
        "        interval_between_frames = 15\n",
        "        number_of_frames = 10\n",
        "        file_name = os.path.basename(video).split('.')[0]\n",
        "\n",
        "        while success and cont < number_of_frames:\n",
        "            success, image = vidcap.read()\n",
        "            if image is None:\n",
        "                break\n",
        "\n",
        "            images.append(image)\n",
        "            vidcap.set(cv2.CAP_PROP_POS_FRAMES, int(vidcap.get(cv2.CAP_PROP_POS_FRAMES)) + interval_between_frames * vidcap.get(cv2.CAP_PROP_FPS))\n",
        "            cont += 1\n",
        "\n",
        "        # Call the remove_rats function to process the extracted frames\n",
        "        result = remove_rats(images)\n",
        "\n",
        "        try:\n",
        "          os.makedirs(image_output, exist_ok=True)\n",
        "        except OSError as e:\n",
        "            print(f'Error: {e}')\n",
        "\n",
        "        output_path = os.path.join(image_output, f\"{file_name}.jpg\")\n",
        "        print(output_path)\n",
        "        cv2.imwrite(output_path, result)"
      ],
      "metadata": {
        "id": "N7ddE2nArf3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imagens:"
      ],
      "metadata": {
        "id": "1Ox4fX7ZKPpQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def contour_properties(contour):\n",
        "  \"\"\"\n",
        "  Computes various properties of a contour.\n",
        "\n",
        "  Args:\n",
        "      contour (numpy.ndarray): Input contour.\n",
        "\n",
        "  Returns:\n",
        "      tuple: Contour properties including area, circularity, radius, bounding box dimensions,\n",
        "              aspect ratio, bounding box coordinates, and centroid coordinates.\n",
        "  \"\"\"\n",
        "  import cv2\n",
        "  import numpy as np\n",
        "\n",
        "  # Calculate moments of the contour\n",
        "  M = cv2.moments(contour)\n",
        "\n",
        "  # Calculate area of the contour\n",
        "  area = cv2.contourArea(contour)\n",
        "\n",
        "  # Calculate perimeter of the contour\n",
        "  perimeter = cv2.arcLength(contour, True)\n",
        "\n",
        "  # Calculate bounding box dimensions and aspect ratio\n",
        "  x, y, w, h = cv2.boundingRect(contour)\n",
        "  aspect_ratio = max(float(w), h) / min(float(w), h) if min(w, h) > 0 else 0\n",
        "\n",
        "  # Calculate minimum enclosing rectangle and circle\n",
        "  rect = cv2.minAreaRect(contour)\n",
        "  circle = cv2.minEnclosingCircle(contour)\n",
        "\n",
        "  # Calculate rectangle coordinates and area\n",
        "  box = cv2.boxPoints(rect)\n",
        "  box = np.int0(box)\n",
        "  rect_area = w * h\n",
        "\n",
        "  # Calculate centroid using different methods\n",
        "  center_x = int(M[\"m10\"] / M[\"m00\"]) if M[\"m00\"] != 0 else 0\n",
        "  center_y = int(M[\"m01\"] / M[\"m00\"]) if M[\"m00\"] != 0 else 0\n",
        "\n",
        "  # Calculate circularity of the contour\n",
        "  circularity = 4 * np.pi * area / (perimeter ** 2) if perimeter > 0 else 0\n",
        "\n",
        "  # Calculate circle properties\n",
        "  (_, _), radius = cv2.minEnclosingCircle(contour)\n",
        "  center_circle = (int(center_x), int(center_y))\n",
        "\n",
        "  # Calculate square properties\n",
        "  cx_quad = int(x)\n",
        "  cy_quad = int(y)\n",
        "\n",
        "  return (area, circularity, radius, x, y, w, h, aspect_ratio,\n",
        "          box, center_circle, center_x, center_y)"
      ],
      "metadata": {
        "id": "pFOv747EJBd-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_contours(frame_name, frame, contours, background):\n",
        "    \"\"\"\n",
        "    Processes contours found in an image, categorizing them based on certain criteria.\n",
        "\n",
        "    Args:\n",
        "        frame_name (str): Name of the frame or image.\n",
        "        frame (numpy.ndarray): Base image for drawing the contours.\n",
        "        contours (list): List of contours found in the image.\n",
        "\n",
        "    Returns:\n",
        "        tuple: Tuple containing the processed image, object count, and dictionary of contour data.\n",
        "    \"\"\"\n",
        "    import cv2\n",
        "\n",
        "    object_count = 0\n",
        "    contour_data = {}  # Dictionary to store data of identified objects\n",
        "\n",
        "    previous_contour = None  # Variável para armazenar o contorno anteriormente escolhido\n",
        "    previous_contour_area = 0  # Variável para armazenar a área do contorno anteriormente escolhido\n",
        "\n",
        "    for contour in contours:\n",
        "        # Approximate the contour with a sequence of line segments\n",
        "        approx = cv2.approxPolyDP(contour, 0.01 * cv2.arcLength(contour, True), True)\n",
        "\n",
        "        # Calculate contour properties\n",
        "        area, circularity, radius, x, y, w, h, aspect_ratio, box, center_circle, cx_circle, cy_circle = contour_properties(contour)\n",
        "\n",
        "        if background == 1:\n",
        "            w += 20\n",
        "\n",
        "        # Check if the contour matches a circular pattern\n",
        "        if area > 2000 and 20 < radius < 100 and  x < 1000 and 150 < y < 400 and 80 < w < 160:\n",
        "            # Limit the radius to a maximum value\n",
        "            max_radius = 100\n",
        "            radius = min(radius, max_radius)\n",
        "            radius = int(radius)\n",
        "\n",
        "            if radius < 80:\n",
        "                radius += 30\n",
        "\n",
        "            # Draw a circular contour\n",
        "            cv2.circle(frame, center_circle, radius, (255, 0, 0), 2)\n",
        "\n",
        "            # Draw the central point\n",
        "            cv2.circle(frame, (cx_circle, cy_circle), 3, (255, 0, 0), -1)\n",
        "\n",
        "            # Increment object count\n",
        "            object_count += 1\n",
        "\n",
        "            # Define the text to be written on the image\n",
        "            text = f\"Object{object_count}\"\n",
        "\n",
        "            # Coordinates where the text will be placed (top-left corner)\n",
        "            coordinates = (cx_circle, cy_circle)\n",
        "\n",
        "            # Specify the font and text size\n",
        "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "            font_size = 0.5\n",
        "            color = (0, 0, 0)  # Text color in BGR (white in this example)\n",
        "\n",
        "            # Add the text to the image\n",
        "            image_with_text = cv2.putText(frame, text, coordinates, font, font_size, color, thickness=2)\n",
        "\n",
        "            # Capture data\n",
        "            contour_data[f\"{frame_name}_{object_count}\"] = [{\n",
        "                \"Form\": \"standard\",\n",
        "                \"object\": object_count,\n",
        "                \"Area\": area,\n",
        "                \"Circularity\": circularity,\n",
        "                \"Width\": w,\n",
        "                \"Height\": h,\n",
        "                \"X\": cx_circle,\n",
        "                \"Y\": cy_circle,\n",
        "                \"Radius\": radius,\n",
        "            }]\n",
        "\n",
        "            # Verifica se o contorno atual contém o contorno anteriormente escolhido\n",
        "            if previous_contour is not None and area > previous_contour_area:\n",
        "                # Define o contorno atual como o contorno anteriormente escolhido\n",
        "                previous_contour = contour\n",
        "                previous_contour_area = area\n",
        "            elif previous_contour is None:\n",
        "                # Define o contorno atual como o contorno anteriormente escolhido\n",
        "                previous_contour = contour\n",
        "                previous_contour_area = area\n",
        "\n",
        "    return frame, contour_data"
      ],
      "metadata": {
        "id": "G7FgojovJewE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_contours(image):\n",
        "    \"\"\"\n",
        "    Finds contours in the input image using the RETR_TREE mode and CHAIN_APPROX_SIMPLE method.\n",
        "\n",
        "    Args:\n",
        "        image (numpy.ndarray): Input image.\n",
        "\n",
        "    Returns:\n",
        "        list: List of contours found in the image.\n",
        "    \"\"\"\n",
        "    import cv2\n",
        "\n",
        "    # Find contours in the image using specified retrieval mode and approximation method\n",
        "    contours, hierarchy = cv2.findContours(image, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    return contours"
      ],
      "metadata": {
        "id": "cGDAVp8DIbGL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_dilation(image):\n",
        "  \"\"\"\n",
        "  Applies dilation to the input image using a defined kernel.\n",
        "\n",
        "  Args:\n",
        "      image (numpy.ndarray): Input image.\n",
        "\n",
        "  Returns:\n",
        "      numpy.ndarray: Dilated image.\n",
        "  \"\"\"\n",
        "  import cv2\n",
        "  import numpy as np\n",
        "\n",
        "  # Define the kernel for dilation\n",
        "  kernel = np.ones((5, 5), np.uint8)\n",
        "\n",
        "  # Perform dilation on the image\n",
        "  dilated_image = cv2.dilate(image, kernel, iterations=3)\n",
        "\n",
        "  return dilated_image"
      ],
      "metadata": {
        "id": "doALuhvvIIEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_threshold(image):\n",
        "  \"\"\"\n",
        "  Applies thresholding to the input image using the Otsu method.\n",
        "\n",
        "  Args:\n",
        "      image (numpy.ndarray): Input image in grayscale format.\n",
        "\n",
        "  Returns:\n",
        "      numpy.ndarray: Thresholded image.\n",
        "  \"\"\"\n",
        "  import cv2\n",
        "\n",
        "  # Compute the gradients using Sobel operators\n",
        "  sobelx = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=3)\n",
        "  sobely = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=3)\n",
        "\n",
        "  # Calculate the magnitude of the gradient\n",
        "  gradient_magnitude = cv2.magnitude(sobelx, sobely)\n",
        "\n",
        "  # Normalize the gradient magnitude\n",
        "  gradient_magnitude = cv2.normalize(gradient_magnitude, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8U)\n",
        "\n",
        "  # Apply thresholding using the Otsu method\n",
        "  _, gradient_threshold = cv2.threshold(gradient_magnitude, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "\n",
        "  return gradient_threshold"
      ],
      "metadata": {
        "id": "iJXfAaMwHTBd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_filters(image, cam=0):\n",
        "  \"\"\"\n",
        "  Applies filters to enhance the input image.\n",
        "\n",
        "  Args:\n",
        "      image (numpy.ndarray): Input image in grayscale format.\n",
        "      cam (boolean): 0 means the field is light, 1 means the field is dark\n",
        "  Returns:\n",
        "      numpy.ndarray: Filtered image.\n",
        "  \"\"\"\n",
        "  import cv2\n",
        "  import numpy as np\n",
        "\n",
        "  if cam:\n",
        "    # Equalize the histogram of the input image\n",
        "    equalized_image = image.copy()\n",
        "  else:\n",
        "    # Equalize the histogram of the input image\n",
        "    equalized_image = cv2.equalizeHist(image)\n",
        "\n",
        "  # Convert the equalized image to float32 format\n",
        "  image32f = np.float32(equalized_image)\n",
        "\n",
        "  # Compute mean and variance using a 3x3 kernel\n",
        "  mu = cv2.blur(image32f, (3, 3))\n",
        "  mu2 = cv2.blur(image32f * image32f, (3, 3))\n",
        "\n",
        "  sigma = cv2.sqrt(mu2 - mu * mu)\n",
        "\n",
        "  # Scale sigma for better visualization\n",
        "  sigma = sigma * 10\n",
        "\n",
        "  # Convert sigma to unsigned 8-bit integer\n",
        "  sigma = sigma.astype(\"uint8\")\n",
        "\n",
        "  # Suppress edges by setting a border region to zero\n",
        "  sigma[:20, :] = 0\n",
        "  sigma[-20:, :] = 0\n",
        "  sigma[:, :20] = 0\n",
        "  sigma[:, -20:] = 0\n",
        "\n",
        "  return sigma"
      ],
      "metadata": {
        "id": "AANq8ghUGiJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_frame(frame, background):\n",
        "  \"\"\"\n",
        "  Processes a single frame from an image file.\n",
        "\n",
        "  Args:\n",
        "      frame (str): The path to the input image file.\n",
        "      background (boolean): 0 means the field is light, 1 means the field is dark\n",
        "\n",
        "  Returns:\n",
        "      tuple: A tuple containing processed results and the image name.\n",
        "  \"\"\"\n",
        "  import cv2\n",
        "  import os\n",
        "\n",
        "  # Read the image from the specified path\n",
        "  image = cv2.imread(frame)\n",
        "\n",
        "  # Extract the image name from the frame path\n",
        "  image_name = os.path.basename(frame).split('.')[0]\n",
        "\n",
        "  # Convert the image to grayscale\n",
        "  gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "  # Apply filters to the grayscale image\n",
        "  filtered_image = apply_filters(gray_image, background)\n",
        "\n",
        "  # Apply thresholding to the filtered image\n",
        "  thresholded_image = apply_threshold(filtered_image)\n",
        "\n",
        "  # Apply dilation to the thresholded image\n",
        "  dilated_image = apply_dilation(thresholded_image)\n",
        "\n",
        "  # Find contours in the dilated image\n",
        "  contours = find_contours(dilated_image)\n",
        "\n",
        "  # Process contours and get results\n",
        "  results = process_contours(image_name, image, contours, background)\n",
        "\n",
        "  # Return processed results and the image name\n",
        "  return results, image_name"
      ],
      "metadata": {
        "id": "5zUyDYWpyupo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset:"
      ],
      "metadata": {
        "id": "v366qGDxVcKo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset_image(dataset):\n",
        "    \"\"\"\n",
        "    Creates a DataFrame from a dataset containing objects with attributes.\n",
        "\n",
        "    Args:\n",
        "        dataset (dict): Dictionary containing objects with attributes.\n",
        "\n",
        "    Returns:\n",
        "        pandas.DataFrame: DataFrame containing objects and their attributes.\n",
        "    \"\"\"\n",
        "    import pandas as pd\n",
        "    # Create an empty list to store objects\n",
        "    object_list = []\n",
        "\n",
        "    # Iterate through the dictionary\n",
        "    for attribute, obj_list in dataset.items():\n",
        "        # Iterate through the list of objects for the current attribute\n",
        "        for obj in obj_list:\n",
        "            # Check if obj is a dictionary\n",
        "            if isinstance(obj, dict):\n",
        "                # Add the object combined with the dictionary {'attribute': attr}\n",
        "                object_list.append({**{'attribute': attribute}, **obj})\n",
        "\n",
        "    # Create the DataFrame based on the object list\n",
        "    df = pd.DataFrame(object_list)\n",
        "\n",
        "    # Return the DataFrame if needed for further use\n",
        "    return df"
      ],
      "metadata": {
        "id": "DBevacOlVb0y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Função Pilar:"
      ],
      "metadata": {
        "id": "z2lp61WNVclz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_system(image_pack, background=0):\n",
        "  \"\"\"\n",
        "  Processes images in the specified image pack and generates results and data.\n",
        "\n",
        "  Args:\n",
        "      image_pack (str): Path to the image pack directory containing JPG images.\n",
        "      background (boolean): 0 means the field is light, 1 means the field is dark\n",
        "  Returns:\n",
        "      None\n",
        "  \"\"\"\n",
        "  import os\n",
        "  import glob\n",
        "  import cv2\n",
        "\n",
        "  dados_gerais = {}\n",
        "\n",
        "  frames_input = glob.glob(os.path.join(image_pack, '*.jpg'))\n",
        "\n",
        "  for frame in frames_input:\n",
        "      results, image_name = process_frame(frame, background)\n",
        "\n",
        "      output_path = os.path.join(image_pack, \"results\")\n",
        "\n",
        "      try:\n",
        "          os.makedirs(output_path, exist_ok=True)\n",
        "      except OSError as e:\n",
        "          print(f'Error creating directory: {e}')\n",
        "\n",
        "      output_image_path = os.path.join(output_path, f\"{image_name}_completed.jpg\")\n",
        "\n",
        "      # Save the resulting image\n",
        "      cv2.imwrite(output_image_path, results[0])\n",
        "      cv2_imshow(results[0])\n",
        "\n",
        "      # Call create_dataset_image function with the generated dataset\n",
        "      dados_frame = create_dataset_image(results[1])\n",
        "\n",
        "      # Update the overall dictionary with image data\n",
        "      dados_gerais.update(results[1])\n",
        "\n",
        "      output_data_path = os.path.join(output_path, f\"{image_name}_data.csv\")\n",
        "\n",
        "      # Save the DataFrame to a CSV file\n",
        "      dados_frame.to_csv(output_data_path, index=False)\n",
        "\n",
        "  # Generate a dataset from the overall dictionary of all images\n",
        "  dataset_geral = create_dataset_image(dados_gerais)\n",
        "\n",
        "  output_all_data_path = os.path.join(image_pack, \"results\", \"all_data.csv\")\n",
        "\n",
        "  # Save the DataFrame to a CSV file\n",
        "  dataset_geral.to_csv(output_all_data_path, index=False)"
      ],
      "metadata": {
        "id": "t4EZcsLqPiQp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Função Explorar"
      ],
      "metadata": {
        "id": "IRWXi5Xw1FTh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Teste da Biblioteca:"
      ],
      "metadata": {
        "id": "WGx98Cvt1NxS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "metadata": {
        "id": "p--_NrKCEo1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "%cd /content/drive/MyDrive/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAexUnToEq50",
        "outputId": "510e9d69-6c49-4594-8fbe-c9af17541749"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n",
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "video_input = glob.glob('/content/drive/MyDrive/Lab eletrofisio ISD/COMPORTAMENTO/Padronização/Exp35-MRO_ contextos_dicas/Exp 35 - rodada 1/*.mp4')\n",
        "raw_image_output = '/content/drive/MyDrive/PPGNeuro/Projeto - Algoritmos/area-Antares/test-exp35'"
      ],
      "metadata": {
        "id": "94nT192DEsnv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#extract_frames(video_input, raw_image_output)"
      ],
      "metadata": {
        "id": "aOKXxov7NWvD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_system(raw_image_output, 0)"
      ],
      "metadata": {
        "id": "WDCtozkkEuFK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}